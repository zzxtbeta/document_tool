# AI 辅助编程实战指南

> AI 不是"免费的初级程序员"，而是"需要精准指挥的超级助手"。你的角色从"代码实现者"升级为"系统设计者"。

---

## 一、认知转变：AI 时代的编程本质

### 1.1 提示词是新的编程语言

你以为你在和 AI 聊天，实际上你在写逻辑。

一句好的 Prompt 能够省掉百行代码。编写提示词本质上是一种新形式的编程——用自然语言定义程序行为。未来的开发者，不再是"只会写代码的人"，而是能与 AI 清晰沟通、精准表达意图的人。

**传统编程**：
```
你写代码 → 调试 → 上线
```

**AI 编程**：
```
你设计架构 → 用提示词描述需求 → AI 写代码 → 你审查把关 → 上线
```

### 1.2 Vibe Coding ≠ 生产级代码

现在的 AI 写代码已经很强了，可以快速验证想法、搭建原型和做重复性的编码任务，但它还存在"能跑但容易埋坑"的问题：

- **安全漏洞**：缺少必要的数据校验和权限控制
- **逻辑隐患**：边缘情况处理不完善
- **隐藏 Bug**：深层次的状态管理问题
- **技术债务**：为了快速实现而牺牲代码质量

如果遇到核心业务逻辑、复杂系统架构、安全性要求高的项目开发，还是需要开发者去严格的设计审查和把关。

**最佳实践**：AI 写 → 人审 → AI 再写 → 人再审

模型一直在进步，今天不行的可能几个月后就行了，我们只需要跟得上节奏。

### 1.3 Know What 比 Know How 更重要

一个资深架构师和一个初级程序员同样用 AI Coding 工具，产出的成果是完全不一样的。

**为什么？** 因为 AI 帮不了你想什么，它只能帮你做什么。

AI 时代，开发者的价值正在迁移：

- **从**：代码工人
- **到**：系统设计者、问题解决者、AI 协作者

**对编程新手而言**：Agent 模式的发展抹平了实现的门槛，你可以快速验证创意、构建原型产品。

**对专业程序员而言**：将自己从繁琐的编码执行中解放出来（在写简易代码方向上，你很难比得过 AI），更专注于架构设计、复杂问题分解和创造性思考。同时，要多基于 AI 快速阅读世界上最优秀的代码，提高代码品味。这才是 AI 时代程序员真正的核心竞争力。

未来编程不再是拼指令，而是拼理解力：

- 不再是 **How to code**
- 而是 **What to build**

### 1.4 会提问比找答案更重要

在 AI 时代，找到答案太容易了。真正难的是——**问出一个有价值的问题**。

不要问：
> "AI 能帮我做些什么？"

而要想：
> "我能与 AI 一起做到什么？"

**未来属于会提问、会思考、会想象的人**：

- **好奇去问** — 保持探索精神
- **系统去想** — 结构化思考能力
- **创造去用** — 将想法落地的能力

用人类智慧提出问题，用人工智能扩展答案。

---

## 二、核心挑战：代码失控与问题分层

### 2.1 真实案例

> **开发者 A**："有个同事在不熟悉 AI Coding 的情况下，用 AI 改了整个模块的代码，我问他也说不清，我怀疑他已经代码失控了"
>
> **开发者 B**："对他来说回滚的沉没成本已经很高了，他那边进度一直延期状态"
>
> **开发者 C**："同时改多个模块，的确需要确认一下修改内容，不然容易崩掉（指脑）"

### 2.2 失控的三个征兆

- AI 一次修改太多文件，无法回溯
- 改了 A 功能，B 功能莫名其妙出 Bug
- AI 的输出越来越偏离你的预期

背后的深层问题：**完全依赖 AI 解决问题，导致能力退化和心态崩塌**。当你在 debug 时也完全依赖 AI，会在一些简单问题上浪费大量时间（AI 有时会一直无法解决某些问题），同时心态非常差（因为解决问题就像在抽卡，你无法预期能否解决、何时解决）。

### 2.3 问题分层思维

AI Coding 中有两类不同性质的问题，需要不同的处理策略：

**Project-Level（项目级）**：
- 特征：整体项目相关，涉及多个/复杂/耦合的模块
- 示例："设计具有某个功能的插件/应用"
- 策略：维护 Context → 与 AI 交流生成 Design Docs → AI Coding 编写 → 反思并更新 Context & Design

**Feature-Level（功能级）**：
- 特征：具体功能相关，涉及单个/少数/独立的问题，需求比较清晰
- 示例："修复某个因为 XX 导致的 bug"
- 策略：**你必须理解问题的完整上下文**，提出解决方案，使用 AI 按你的思路解决问题，而非让它替你解决

关键洞察：Feature-Level 问题是 AI Coding 的"最后一公里"和"Demo to Production"的关键环节。如果这类问题都完全依赖 AI，你很难有任何进步，相反绝大部分能力都会退步。

### 2.4 根本原因与解决方案

**根本原因**：
```
模糊需求 + 无结构化管理 + 能力不对齐 = 代码失控
```

**解决方案**：
```
规范化工作流 + 可追溯的变更记录 + 掌握细节 = 可控交付
```

---

## 三、上下文工程：AI 的导航系统

AI 不是"全知全能"，它只知道你告诉它的信息。上下文质量直接决定输出质量。

**核心洞察**：维护个人 Context 不是为了帮模型提升性能，而是**为了帮模型对齐你自己**。模型的能力超过绝大部分个人，Context 是为了让模型以你能理解的方式给出回答。所以：

- **构建 Context 是必要的**（让模型对齐你的能力）
- **反思和更新 Context 也是必要的**（让你对齐模型的能力）
- 二者缺一不可

### 3.1 两类关键 Context

**Tech Context（技术上下文）**：
- 内容：技术栈偏好、开发理念、常用模式
- 特点：与个人技术背景挂钩，跨项目通用
- 存放：个人知识库（如 iCloud、Obsidian），方便任何情况下复制粘贴
- 示例：优先使用 TypeScript、偏好函数式编程、推崇 SOLID 原则

**Dev Context（开发上下文）**：
- 内容：代码风格、系统设计偏好、项目特定约定
- 特点：与项目主题挂钩（全栈开发和 AI Agent 的 Dev Context 是不同的）
- 存放：项目根目录（如 `AGENTS.md`、`.cursorrules`）或项目文档

### 3.2 创建项目上下文文件

大多数 AI 编程工具支持项目级配置文件（如 `CLAUDE.md`、`.cursorrules`、`.aidigestrc`、`AGENTS.md` 等），这是记录项目关键信息的理想位置。

**必须提供的上下文**：

- **常用命令**：`npm run build`、`pytest`、`make test`
- **架构说明**：项目整体结构、模块划分
- **代码规范**：命名规则、注释要求、格式化标准
- **技术栈版本**：Python 3.11、FastAPI 0.104、PostgreSQL 17...
- **核心文件**：关键模块和工具函数的位置
- **测试说明**：如何运行测试、测试覆盖要求
- **安全要求**：数据校验、权限控制、敏感信息处理
- **性能要求**：响应时间、并发量、资源限制
- **工作流程**：分支命名、提交规范、代码审查流程

**示例配置**：

```markdown
# 构建命令
- npm run build: 构建项目
- npm run typecheck: 运行类型检查器
- npm test: 运行测试套件

# 代码风格
- 使用 ES 模块（import/export）语法，而不是 CommonJS（require）
- 尽可能解构导入（例如 import { foo } from 'bar'）
- 函数名使用驼峰命名法，组件名使用 PascalCase

# 架构
- src/components: 可复用 UI 组件
- src/services: 业务逻辑层
- src/utils: 工具函数

# 工作流程
- 完成一系列代码更改后，请确保进行类型检查
- 为了性能考虑，优先运行单个测试，而不是整个测试套件
- 每个功能开发完成后立即提交
```

### 3.2 优化上下文文件

上下文文件会成为 AI 提示的一部分，应该像优化提示词一样优化它：

- **迭代测试**：不要一次性添加大量内容，而是逐步添加并测试有效性
- **强调重点**：对关键指令添加"重要"、"必须"等强调词
- **保持简洁**：只保留真正有用的信息
- **使用示例**：提供具体的代码示例比抽象描述更有效

### 3.3 保持上下文清洁与持续迭代

- 定期清理过时信息
- 移除不再使用的技术栈
- 更新版本号和依赖
- 删除已完成功能的临时说明

在长时间会话中，及时清理对话上下文，防止 AI 被无关信息干扰。

**Context 的技术复利**：

维护良好的 Tech/Dev Context 会在后续项目开发中节省大量时间。当你遇到 Feature-Level 问题时，这正是反思并更新 Context 的最佳时机：

- 是你的 Design 中缺少了什么吗？
- 是你的描述（Prompt）存在歧义吗？
- 是你需要补充启发式的 guidance 吗？

任何收获和反思都应手动更新到 Tech/Dev Context 中，这就是产生技术复利的关键。

---

## 四、提示词工程：精准表达意图

### 4.1 提示词质量层级

**核心原则**：提示词质量 = 代码质量。不是"写需求"，是"写清楚需求"。

| 层级 | 描述方式 | 示例 | 成功率 |
|-----|---------|------|--------|
| **基础级** | 只说"做什么" | "写个登录页面" | 30% |
| **明确级** | "做什么" + "用什么技术" | "用 React+TS 写个登录页面" | 50% |
| **详细级** | "做什么" + "怎么做" + "做到什么程度" | "用 React Hook Form 处理表单，密码需包含大小写+数字，登录成功跳转首页，失败用 Antd Message 提示，附带单元测试" | 80% |
| **规格级** | 需求文档 + 设计稿 + 验收标准 | 完整 PRD + UI 设计 + 测试用例（OpenSpec/Kiro 模式） | 95% |

### 4.2 编写高质量提示词的原则

**具体性**：与 AI 的沟通应被视为一种严肃的工程行为。模糊的指令必然导致不可靠的输出。提示应如同 API 文档般精确，明确指出要操作的文件、函数、类以及预期的行为。沟通的精度，直接决定了协作的效率和产出的质量。

对比示例：

| 模糊表达 | 具体表达 |
|---------|---------|
| 修复一下 Bug | 【登录 Bug】用户输入错误的用户名或密码后，页面卡死并显示为空白，无法进行任何操作。复现步骤：1. 打开登录页 2. 输入错误凭据 3. 点击登录。预期：显示错误提示。 |
| 为 foo.py 添加测试 | 为 foo.py 编写新的测试用例，涵盖用户注销时的边缘情况。避免使用 mock |
| 为什么 ExecutionFactory 有这么奇怪的 api？ | 查看 ExecutionFactory 的 git 历史并总结其 api 是如何形成的 |
| 添加日历小部件 | 查看主页上现有小部件的实现方式以了解模式，特别是代码和接口是如何分离的。HotDogWidget.php 是一个很好的开始示例。然后，按照模式实现一个新的日历小部件，让用户选择月份并向前/向后翻页选择年份。从头构建，不使用代码库中已使用的库之外的库。 |

**提供视觉输入**：

- 粘贴 UI 设计稿截图
- 提供期望输出的示例图片
- 拖放错误信息的截图
- 给出文件路径让 AI 读取图像

**明确文件范围**：

- 使用 Tab 补全快速引用文件或文件夹
- 明确告诉 AI 只修改特定文件
- 列出需要 AI 查看的相关文件

**提供 URL**：

- 直接粘贴文档链接让 AI 阅读
- 引用 API 文档、设计规范等在线资源

### 4.3 让 AI 帮你优化提示词

```
你: "我想开发一个登录网站，请先帮我优化提示词，要求完善需求分析、方案设计和技术选型"
AI: (生成结构化需求文档)
你: (基于优化后的需求继续开发)
```

这种"元提示"技巧能显著提升最终输出质量。

---

## 五、工作流模式：经过验证的实践

### 5.1 自然语言编程范式

当模型能力超过"那个边界"后，编程范式已经在逐步转移至"自然语言编程"。这种范式最大的优势是**极简单/极快速的开始**——你可以在任意时间开始编程，只需要把思考和目标等 prompt 写在备忘录等文本编辑软件中，在有空时让 AI 帮你进行编码。

这极大地利用了零碎时间。传统编码是一个"冷启动"的过程（打开电脑、打开 IDE、构思并以具体语言编写代码），而自然语言编程可以随时随地开始。

当然，自然语言编程一定会出现各种 corner case，我们对此需要宽容一些，就像你用编程语言编码时会出现 bug 一样。但这同样是一个积累的过程，这就是为什么 Context 如此重要。

### 5.2 Talk to Design Docs 工作流

对于 Project-Level 问题，最重要的是如何构建一个准确、符合 AI Coding Best Practice 的设计文档。推荐流程：

**步骤 1：与 AI 对话设计**
- 打开 AI 聊天工具，粘贴 Tech Context
- 简述设计目标，一步步讨论系统架构、细节
- 让 AI 提出当前设计中可能的问题和存在模糊/歧义的地方

**步骤 2：深入细节**
- 在对话中深入任何细节，解决任何困惑
- 当设计足够完善后，让 AI 基于当前对话历史生成最终的 Design Docs

**步骤 3：反思与更新**
- 在与 AI 交流的过程中，任何收获和反思都应手动更新到 Tech/Dev Context
- 这就是产生技术复利的关键

### 5.3 探索-计划-编码-提交

这种多功能工作流程适合大多数开发任务：

**步骤 1：探索**
- 要求 AI 读取相关文件、图像或 URL
- 提供一般指针或特定文件名
- 明确告诉它暂时不要编写任何代码
- 对于复杂问题，考虑使用子会话验证细节

**步骤 2：规划**
- 要求 AI 制定如何处理问题的计划
- 让 AI 充分思考，评估不同方案
- 如果计划合理，可以创建文档记录
- 这样如果实施不理想，可以回退到这个点

**步骤 3：实施**
- 要求 AI 在代码中实施解决方案
- 要求它在实施各个部分时验证合理性
- 保持范围聚焦，避免过度修改

**步骤 4：提交**
- 要求 AI 提交结果并创建拉取请求
- 更新相关文档（README、CHANGELOG 等）

关键：步骤 1-2 至关重要。没有它们，AI 倾向于直接跳到编码，容易导致方向错误。

### 5.4 测试驱动开发（TDD）

这是用于可通过测试轻松验证的更改的最佳工作流程。成功的实践是在编写功能代码之前先让 AI 生成对应的测试用例（可以写在配置文件或 system rules 中）。随后，AI 的任务就变成了"通过所有测试"。这个简单的流程转变，创建了一个能自我修正的闭环，极大提升了可靠性。

**步骤 1：编写测试**
- 要求 AI 基于预期的输入/输出对编写测试
- 明确说明你在进行 TDD，避免创建 mock 实现
- 即使功能尚不存在也先写测试

**步骤 2：确认失败**
- 告诉 AI 运行测试并确认它们失败
- 明确告诉它不要编写任何实现代码

**步骤 3：提交测试**
- 当你对测试满意时，要求 AI 提交测试

**步骤 4：实施功能**
- 要求 AI 编写通过测试的代码
- 指示它不要修改测试
- 让 AI 迭代直到所有测试通过

**步骤 5：提交代码**
- 一旦满意就要求 AI 提交代码

AI 在有明确目标进行迭代时表现最佳。测试提供了清晰的成功标准。

**实践建议**：可以在项目中构建 `lint.sh` 和 `unittest.sh` 脚本，分别代表代码规范和单元测试。在配置文件或 `CONTRIBUTING.md` 中告诉 AI 需要撰写并通过这些检查。这样简单的设置能让代码可用性高不少。

### 5.3 视觉反馈迭代

适用于 UI 开发和需要视觉验证的场景：

**步骤 1：提供工具**
- 为 AI 提供截取浏览器截图的方法
- 或准备好手动复制/粘贴截图

**步骤 2：提供设计稿**
- 通过复制/粘贴或拖放提供视觉模拟
- 或给出图像文件路径

**步骤 3：实施与迭代**
- 要求 AI 实现设计
- 让 AI 截取结果的截图
- 迭代直到其结果与模拟匹配

**步骤 4：提交**
- 当满意时要求 AI 提交

AI 的输出往往通过 2-3 次迭代显著改善。为 AI 提供查看其输出的工具以获得最佳结果。

### 5.5 培养任务分类直觉：何时放手，何时掌控

高效协作的前提是做出正确的决策：何时放手，何时掌控。开发者需要培养一种直觉，能够快速判断一个任务是适合"Agent"模式的外围探索，还是需要"Ask"模式的核心构建。这种判断力，是区分普通使用者与高级玩家的关键。

**Agent 模式（放手）**：
- 适用场景：Project-Level 问题，原型构建，探索性开发
- 特点：让 AI 自主工作，完成度优先
- 风险：可能偏离预期，需要后续调整

**Ask 模式（掌控）**：
- 适用场景：Feature-Level 问题，核心业务逻辑，关键功能
- 特点：你理解问题、提出方案，AI 按你的思路执行
- 价值：保持对细节的掌握，避免能力退化

### 5.6 及早且经常地纠正路线

虽然让 AI 自主工作很诱人，但通过成为积极的协作者并指导 AI 的方法，你通常会获得更好的结果。

**路线纠正工具**：

- **要求制定计划**：明确告诉 AI 在你确认其计划前不要编码
- **中断执行**：在任何阶段中断 AI，保留上下文，然后重定向或扩展指令
- **回退历史**：编辑之前的提示，探索不同的方向
- **要求撤销**：让 AI 撤销更改，然后采取不同的方法

虽然 AI 偶尔在第一次尝试时完美解决问题，但使用这些纠正工具通常能更快地产生更好的解决方案。

### 5.5 对复杂工作流程使用检查清单

对于具有多个步骤或需要详尽解决方案的大型任务——如代码迁移、修复大量 lint 错误或运行复杂构建脚本——通过让 AI 使用 Markdown 文件作为检查清单和工作草稿本来提高性能。

例如，要修复大量 lint 问题：

1. 告诉 AI 运行 lint 命令并将所有结果错误（带有文件名和行号）写入 Markdown 检查清单
2. 指示 AI 逐一解决每个问题，修复和验证后再勾选并移至下一个

---

## 六、OpenSpec 工作流：规格驱动开发

### 6.1 问题：为什么 AI 会"失控"？

**传统 AI 协作流程**：

```
你: "帮我加个搜索功能"
AI: "好的，我修改了 10 个文件"
你: "等等，我只是想加个简单的搜索..."
AI: "我已经重构了整个数据层..."
```

**核心矛盾**：需求在聊天记录里，AI 根据"猜测"行动，没有明确的"设计图纸"。AI coding assistants 在需求模糊时会产生不可预测的输出，常常遗漏需求或添加不需要的功能。

**解决方案**：OpenSpec 添加了一个轻量级的规格工作流，在实施前锁定意图，给你确定的、可审查的输出。

### 6.2 OpenSpec 工作流：先规划，再动手

OpenSpec 强制 AI 遵循工程化流程：

```
┌────────────────────┐
│ 1. 起草提案        │  你和 AI 对齐"要做什么"
│ (Draft Proposal)   │  → 输出：需求文档 + 任务清单
└────────┬───────────┘
         │ share intent with your AI
         ▼
┌────────────────────┐
│ 2. 评审对齐        │  人工检查，确保理解一致
│ (Review & Align)   │◀──── feedback loop ──────┐
└────────┬───────────┘                          │
         │ approved plan                        │
         ▼                                      │
┌────────────────────┐                          │
│ 3. 实施任务        │  AI 严格按任务清单写代码  │
│ (Implement Tasks)  │──────────────────────────┘
└────────┬───────────┘
         │ ship the change
         ▼
┌────────────────────┐
│ 4. 归档更新        │  变更记录永久保存，可追溯
│ (Archive & Update) │
└────────────────────┘
```

### 6.3 OpenSpec 的关键优势

**轻量级**：
- 简单的工作流程
- 无需 API keys
- 最小化设置

**Brownfield-first（适合已有项目）**：
- OpenSpec 分离了真实状态和提案：`openspec/specs/`（当前真相）和 `openspec/changes/`（提案更新）
- 这使得差异明确且可管理，特别适合跨功能修改

**变更追踪**：
- 提案、任务和规格 delta 统一存放
- 归档时将批准的更新合并回规格

**对比表**：

| 特性 | 传统 AI 协作 | OpenSpec 工作流 |
|-----|------------|----------------|
| 需求存储 | 聊天记录里，容易遗忘 | 固化为文档，AI 必须遵守 |
| 范围控制 | AI 自由发挥，容易偏离 | 任务清单约束，防止过度修改 |
| 变更追溯 | 改了什么不清楚 | 每次变更有提案记录，可追溯 |
| 团队协作 | AI 理解不一致 | 团队共享同一份规格说明 |
| 工具支持 | 依赖特定工具 | 支持多种 AI 工具（Claude Code、Cursor、Codex 等） |

**类比**：
- **传统方式**：口头告诉包工头"我想要个两层小楼"，他自由发挥
- **OpenSpec**：先出施工图纸，包工头必须按图纸施工，完工后留存档案

### 6.4 OpenSpec 快速上手

**安装与初始化**：

```bash
# 1. 全局安装 OpenSpec
npm install -g @fission-ai/openspec@latest

# 2. 在项目目录初始化
cd your-project
openspec init

# 3. 选择你使用的 AI 工具（Claude Code、Cursor、Codex 等）
# OpenSpec 会自动配置相应的 slash 命令
```

**创建第一个变更**：

```
你: 创建 OpenSpec 提案：添加用户搜索过滤器
    (或使用快捷命令: /openspec:proposal Add profile search filters)

AI: 我将创建 OpenSpec 变更提案
    创建: openspec/changes/add-profile-filters/
    ├── proposal.md      # 变更原因和内容
    ├── tasks.md         # 实现检查清单
    └── specs/           # 规格 delta（显示变更）

你: 审查提案，验证是否符合预期
    $ openspec show add-profile-filters

你: 提案看起来不错，开始实施
    (或使用快捷命令: /openspec:apply add-profile-filters)

AI: 按任务清单实施
    Task 1.1 ✓ Task 1.2 ✓ Task 2.1 ✓

你: 完成后归档变更
    (或使用快捷命令: /openspec:archive add-profile-filters)
    
AI: 归档完成，规格已更新，准备下一个功能！
```

### 6.5 实际效果对比

**Before（代码失控）**：

```
你: "加个用户搜索功能"
AI: 修改了 12 个文件，重构了数据库，顺便改了登录逻辑
你: "???" (回滚成本巨大，进度延期)
```

**After（使用 OpenSpec）**：

```
你: "创建提案: 添加用户搜索功能"
AI: 生成提案 → 3 个任务:
    - 1.1 添加搜索 API 接口
    - 1.2 前端搜索框组件
    - 1.3 编写单元测试
你: 审查提案 → 批准
AI: 只修改 3 个文件，按任务清单完成
你: 可控、可追溯、可回滚
```

---

## 七、项目管理最佳实践

### 7.1 原子化提交：随时可回滚

- **规则**：AI 每次生成代码后立即 `git commit`
- **价值**：发现 AI 走错路，立即回滚，避免越陷越深

### 7.2 模块化设计：避免重复造轮子

- **规则**：要求 AI 先抽象通用组件（如"分页列表组件"）
- **价值**：新功能复用模块，项目线性扩展

### 7.3 范围限定：一次只改一个任务

- **规则**：明确告诉 AI "只修改 `UserService.java`"
- **价值**：防止"修一个 Bug，引入十个 Bug"

### 7.4 强制验证：AI 自检

- **规则**：要求 AI 生成代码后自动运行测试或编译检查
- **价值**：尽早发现低级错误

### 7.5 工具配置优化

- **规则**：在工具的配置文件中设置"直接输出代码，省略解释"
- **价值**：提升效率，减少冗余输出

---

## 八、高级技巧与场景

### 8.1 代码库问答

在接触新代码库时，使用 AI 进行学习和探索。你可以向 AI 询问在结对编程时会向项目中其他工程师询问的相同类型问题：

- 日志记录是如何工作的？
- 如何创建新的 API 端点？
- `foo.rs` 第 134 行的 `async move { ... }` 是做什么的？
- `CustomerOnboardingFlowImpl` 处理哪些边缘情况？
- 为什么我们在第 333 行调用 `foo()` 而不是 `bar()`？
- `baz.py` 第 334 行在 Java 中的等价物是什么？

这种方式可以显著改善上手时间并减少其他工程师的负担。

### 8.2 使用 AI 与 Git 交互

AI 可以有效处理许多 git 操作：

- **搜索 git 历史**：回答诸如"v1.2.3 中包含了哪些更改？"、"谁拥有这个特定功能？"等问题
- **编写提交消息**：AI 会自动查看你的更改和最近的历史来编写考虑所有相关上下文的消息
- **处理复杂操作**：如还原文件、解决变基冲突以及比较和移植补丁

### 8.3 使用 AI 与 GitHub 交互

AI 可以管理许多 GitHub 交互：

- **创建拉取请求**：基于差异和周围上下文生成适当的提交消息
- **实施代码审查意见**：告诉 AI 修复 PR 上的评论，完成后推送回 PR 分支
- **修复失败的构建**或 linter 警告
- **分流和分类开放问题**：循环遍历开放的 GitHub 问题并分配适当的标签

### 8.4 多会话并行工作

对于多个独立任务，可以：

**方案 1：多个工作目录**
1. 在单独的文件夹中创建 3-4 个 git 检出
2. 在单独的终端标签中打开每个文件夹
3. 在每个文件夹中启动 AI 会话，执行不同的任务
4. 循环检查进度并批准/拒绝请求

**方案 2：使用 git worktrees**
- 更轻量级的替代方案
- 允许将同一仓库的多个分支检出到单独的目录中
- 每个 worktree 都有自己的工作目录和隔离的文件
- 同时共享相同的 Git 历史和 reflog

**方案 3：多个 AI 验证**
- 让一个 AI 编写代码
- 使用另一个 AI 审查或测试它
- 启动第三个 AI 阅读代码和审查反馈
- 让这个 AI 基于反馈编辑代码

这种分离通常比让单个 AI 处理所有事情产生更好的结果。

### 8.5 先设计，后编码

- **先描述产品"感觉"（Vibe）和用户流程**，再让 AI 实现
- **尽早命名**：确定清晰的模块/组件名称，AI 会贯彻始终
- **多问"为什么"**："为何选择这个方案而非另一种？"逼 AI 暴露假设

---

## 九、总结：从使用工具到重塑工作流

AI 辅助编程不是让 AI 替你写代码，而是让你从更高的维度去思考和设计系统。AI 对软件开发的影响，正从单纯的"效率工具"演变为深刻的"工作流重塑"。

现在 AI 的问题不再是"能写什么代码？"，而是"如何与 AI 协同，以最高效、最可靠的方式完成整个项目？"

**关键要点**：

1. **提示词是新的编程语言** — 学会精准表达意图，一句好的 Prompt 能够省掉百行代码
2. **Vibe Coding ≠ 生产级** — AI 写，人审，迭代验证；AI 时代仍需要严格的设计审查
3. **Know What > Know How** — 理解力决定产出质量；架构师和初级程序员用同样工具，产出完全不同
4. **会提问比找答案更重要** — 问题定义能力是核心竞争力
5. **问题分层思维** — Project-Level 让 AI 探索，Feature-Level 保持掌控，避免能力退化
6. **上下文工程** — 维护 Tech/Dev Context 不是为了提升模型性能，而是让模型对齐你的理解
7. **工作流规范** — Talk to Design Docs、TDD、探索-计划-编码-提交，建立自我验证闭环
8. **OpenSpec 思想** — 先规划再动手，需求固化为文档，可追溯可回滚

**对不同角色的价值**：

- **编程新手**：Agent 模式抹平实现门槛，快速验证创意、构建原型
- **专业程序员**：从编码执行中解放，专注架构设计、问题分解和创造性思考；基于 AI 快速阅读优秀代码，提高代码品味

记住：AI 是工具，你是架构师。工具会越来越强大，但你的价值在于：
- 知道要构建什么（What to build）
- 为什么构建（Why）
- 如何设计（How to design）

未来属于会提问、会思考、会想象的人。用人类智慧提出问题，用人工智能扩展答案。

---

## 参考资料

- [OpenSpec 官方文档](https://github.com/Fission-AI/OpenSpec) — Spec-driven development for AI coding assistants
- [Claude Code 最佳实践](https://www.anthropic.com/engineering/claude-code-best-practices)
- [Awesome Claude Code](https://github.com/hesreallyhim/awesome-claude-code)
- [Anthropic Skills](https://github.com/anthropics/skills)
- [上下文工程实践](https://github.com/yzfly/awesome-context-engineering)
- https://mp.weixin.qq.com/s/6j-MqSrJz5YlKAe2LZW6pg
