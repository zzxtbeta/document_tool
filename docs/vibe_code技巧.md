# AI 辅助编程实战指南

> **核心洞察**: AI 不是"免费的初级程序员"，而是"需要精准指挥的超级助手"  
> 你的角色从"代码实现者"升级为"系统设计者"

---

## 一、认知转变：AI 时代的编程本质

### 1.1 Prompt 是新的编程语言

**你以为你在和 AI 聊天？不，你在写逻辑。**

正如我们平时工作中拒绝接受"一句话需求"，和 AI 沟通时也应避免模糊表达。这和与同事沟通是一样的——如果表达不清楚，对方不知道要做什么，交付的产物自然五花八门。

**Prompt 的质量直接决定 AI 交付结果的质量。** 一句精准的 Prompt 能省掉百行代码,编写提示词本质上是一种新形式的编程——用自然语言定义程序行为。

未来的开发者，不再是"只会写代码的人"，而是**能与 AI 清晰沟通、精准表达意图的人**。

**编程范式的转变**：

| 传统编程 | AI 辅助编程 |
|---------|------------|
| 你写代码 → 调试 → 上线 | 你设计架构 → 用 Prompt 描述需求 → AI 写代码 → 你审查把关 → 上线 |
| 关注 "How to code" | 关注 "What to build" |
| 体力活为主 | 脑力活为主 |

### 1.2 Vibe Coding ≠ 生产级代码

⚠️ **重要警示**: AI 认为的"完成"，可能并不是实际的完成。

现在的 AI 写代码已经很强了，可以快速验证想法、搭建原型和做重复性的编码任务，但它还存在"能跑但容易埋坑"的问题：

- **安全漏洞**：缺少必要的数据校验和权限控制
- **逻辑隐患**：边缘情况处理不完善  
- **隐藏 Bug**：深层次的状态管理问题
- **技术债务**：为了快速实现而牺牲代码质量
- **幻觉问题**：上下文过长时容易遗忘或产生错误理解

**核心业务逻辑、复杂系统架构、安全性要求高的项目**，仍需开发者严格的设计审查和把关。

**最佳实践**: AI 写 → 人审 → AI 再写 → 人再审（防御性编程思维）

💡 模型一直在进步，今天不行的可能几个月后就行了，我们只需要跟得上节奏。

### 1.3 Know What 比 Know How 更重要

**关键洞察**: 一个资深架构师和一个初级程序员同样用 AI Coding 工具，产出的成果完全不同。

**为什么？** 因为 AI 帮不了你想什么，它只能帮你做什么。

AI 时代，开发者的价值正在迁移：

| 传统价值 | AI 时代价值 |
|---------|------------|
| 代码工人 | 系统设计者 |
| 执行者 | 问题解决者 |
| 独立编码 | AI 协作者 |
| How to code | What to build |

**对编程新手而言**:  
Agent 模式的发展抹平了实现的门槛，你可以快速验证创意、构建原型产品。这是前所未有的机会——**想法可以更快变成现实**。

**对专业程序员而言**:  
将自己从繁琐的编码执行中解放出来（在写简易代码方向上，你很难比得过 AI），更专注于：
- 架构设计
- 复杂问题分解  
- 创造性思考
- 基于 AI 快速阅读世界上最优秀的代码，提高代码品味

这才是 AI 时代程序员真正的核心竞争力。

💡 **未来编程不再是拼指令，而是拼理解力**

### 1.4 会提问比找答案更重要

在 AI 时代，找到答案太容易了。真正难的是——**问出一个有价值的问题**。

不要问：
> "AI 能帮我做些什么？"

而要想：
> "我能与 AI 一起做到什么？"

**未来属于会提问、会思考、会想象的人**：

- **好奇去问** — 保持探索精神
- **系统去想** — 结构化思考能力
- **创造去用** — 将想法落地的能力

用人类智慧提出问题，用人工智能扩展答案。

---

## 二、核心挑战：代码失控与问题分层

### 2.1 真实案例

> **开发者 A**："有个同事在不熟悉 AI Coding 的情况下，用 AI 改了整个模块的代码，我问他也说不清，我怀疑他已经代码失控了"
>
> **开发者 B**："对他来说回滚的沉没成本已经很高了，他那边进度一直延期状态"
>
> **开发者 C**："同时改多个模块，的确需要确认一下修改内容，不然容易崩掉（指脑）"

### 2.2 失控的三个征兆

- AI 一次修改太多文件，无法回溯
- 改了 A 功能，B 功能莫名其妙出 Bug
- AI 的输出越来越偏离你的预期

背后的深层问题：**完全依赖 AI 解决问题，导致能力退化和心态崩塌**。当你在 debug 时也完全依赖 AI，会在一些简单问题上浪费大量时间（AI 有时会一直无法解决某些问题），同时心态非常差（因为解决问题就像在抽卡，你无法预期能否解决、何时解决）。

### 2.3 问题分层思维：何时放手，何时掌控

高效协作的前提是做出正确的决策：**何时放手，何时掌控**。开发者需要培养一种直觉，快速判断任务适合哪种模式。

| 维度 | Project-Level（项目级） | Feature-Level（功能级） |
|-----|----------------------|---------------------|
| **特征** | 整体项目相关，涉及多个/复杂/耦合的模块 | 具体功能相关，涉及单个/少数/独立的问题 |
| **示例** | "设计具有某个功能的插件/应用" | "修复某个因为 XX 导致的 bug" |
| **策略** | 维护 Context → 与 AI 交流生成 Design Docs → AI Coding 编写 → 反思并更新 Context & Design | **你必须理解问题的完整上下文**，提出解决方案，使用 AI 按你的思路解决问题 |
| **模式** | Agent 模式（放手） | Ask 模式（掌控） |
| **风险** | 可能偏离预期，需要后续调整 | 需要你有足够的理解力 |

⚠️ **关键洞察**: Feature-Level 问题是 AI Coding 的"最后一公里"和"Demo to Production"的关键环节。

如果这类问题都完全依赖 AI，你很难有任何进步，相反绝大部分能力都会退步。这是区分普通使用者与高级玩家的关键。

### 2.4 根本原因与解决方案

**根本原因**：
```
模糊需求 + 无结构化管理 + 能力不对齐 = 代码失控
```

**解决方案**：
```
规范化工作流 + 可追溯的变更记录 + 掌握细节 = 可控交付
```

---

## 三、上下文工程：AI 的导航系统

> **Karpathy 的新概念**: "Context Engineering" 正在取代 "Prompt Engineering"

AI 不是"全知全能"，它只知道你告诉它的信息。**上下文质量直接决定输出质量。**

### 核心洞察

维护个人 Context 不是为了帮模型提升性能，而是**为了帮模型对齐你自己**。

模型的能力超过绝大部分个人，Context 是为了让模型以你能理解的方式给出回答。因此：

```
构建 Context（让模型对齐你的能力）
        ⬇
反思和更新 Context（让你对齐模型的能力）  
        ⬇
    技术复利
```

二者缺一不可，这是产生技术复利的关键。

### 3.1 两类关键 Context

**Tech Context（技术上下文）**：
- 内容：技术栈偏好、开发理念、常用模式
- 特点：与个人技术背景挂钩，跨项目通用
- 存放：个人知识库（如 iCloud、Obsidian），方便任何情况下复制粘贴
- 示例：优先使用 TypeScript、偏好函数式编程、推崇 SOLID 原则

**Dev Context（开发上下文）**：
- 内容：代码风格、系统设计偏好、项目特定约定
- 特点：与项目主题挂钩（全栈开发和 AI Agent 的 Dev Context 是不同的）
- 存放：项目根目录（如 `AGENTS.md`、`.cursorrules`）或项目文档

### 3.2 创建项目上下文文件

大多数 AI 编程工具支持项目级配置文件（如 `CLAUDE.md`、`.cursorrules`、`.aidigestrc`、`AGENTS.md` 等），这是记录项目关键信息的理想位置。

**必须提供的上下文**：

- **常用命令**：`npm run build`、`pytest`、`make test`
- **架构说明**：项目整体结构、模块划分
- **代码规范**：命名规则、注释要求、格式化标准
- **技术栈版本**：Python 3.11、FastAPI 0.104、PostgreSQL 17...
- **核心文件**：关键模块和工具函数的位置
- **测试说明**：如何运行测试、测试覆盖要求
- **安全要求**：数据校验、权限控制、敏感信息处理
- **性能要求**：响应时间、并发量、资源限制
- **工作流程**：分支命名、提交规范、代码审查流程

**示例配置**：

```markdown
# 构建命令
- npm run build: 构建项目
- npm run typecheck: 运行类型检查器
- npm test: 运行测试套件

# 代码风格
- 使用 ES 模块（import/export）语法，而不是 CommonJS（require）
- 尽可能解构导入（例如 import { foo } from 'bar'）
- 函数名使用驼峰命名法，组件名使用 PascalCase

# 架构
- src/components: 可复用 UI 组件
- src/services: 业务逻辑层
- src/utils: 工具函数

# 工作流程
- 完成一系列代码更改后，请确保进行类型检查
- 为了性能考虑，优先运行单个测试，而不是整个测试套件
- 每个功能开发完成后立即提交
```

### 3.2 优化上下文文件

上下文文件会成为 AI 提示的一部分，应该像优化提示词一样优化它：

- **迭代测试**：不要一次性添加大量内容，而是逐步添加并测试有效性
- **强调重点**：对关键指令添加"重要"、"必须"等强调词
- **保持简洁**：只保留真正有用的信息
- **使用示例**：提供具体的代码示例比抽象描述更有效

### 3.3 保持上下文清洁与持续迭代

- 定期清理过时信息
- 移除不再使用的技术栈
- 更新版本号和依赖
- 删除已完成功能的临时说明

在长时间会话中，及时清理对话上下文，防止 AI 被无关信息干扰。

**Context 的技术复利**：

维护良好的 Tech/Dev Context 会在后续项目开发中节省大量时间。当你遇到 Feature-Level 问题时，这正是反思并更新 Context 的最佳时机：

- 是你的 Design 中缺少了什么吗？
- 是你的描述（Prompt）存在歧义吗？
- 是你需要补充启发式的 guidance 吗？

任何收获和反思都应手动更新到 Tech/Dev Context 中，这就是产生技术复利的关键。

---

## 四、提示词工程：精准表达意图

> **核心原则**: 提示词质量 = 代码质量  
> 不是"写需求"，是"写清楚需求"

在开始使用 AI Coding 之前，**系统学习 Prompt 技巧是必要的**，对后续使用效果影响很大。

### 4.1 提示词质量层级

| 层级 | 描述方式 | 示例 | 成功率 |
|-----|---------|------|--------|
| **基础级** | 只说"做什么" | "写个登录页面" | 30% |
| **明确级** | "做什么" + "用什么技术" | "用 React+TS 写个登录页面" | 50% |
| **详细级** | "做什么" + "怎么做" + "做到什么程度" | "用 React Hook Form 处理表单，密码需包含大小写+数字，登录成功跳转首页，失败用 Antd Message 提示，附带单元测试" | 80% |
| **规格级** | 需求文档 + 设计稿 + 验收标准 | 完整 PRD + UI 设计 + 测试用例（OpenSpec/Kiro 模式） | 95% |

### 4.2 编写高质量提示词的原则

**具体性**：与 AI 的沟通应被视为一种严肃的工程行为。模糊的指令必然导致不可靠的输出。提示应如同 API 文档般精确，明确指出要操作的文件、函数、类以及预期的行为。沟通的精度，直接决定了协作的效率和产出的质量。

对比示例：

| 模糊表达 | 具体表达 |
|---------|---------|
| 修复一下 Bug | 【登录 Bug】用户输入错误的用户名或密码后，页面卡死并显示为空白，无法进行任何操作。复现步骤：1. 打开登录页 2. 输入错误凭据 3. 点击登录。预期：显示错误提示。 |
| 为 foo.py 添加测试 | 为 foo.py 编写新的测试用例，涵盖用户注销时的边缘情况。避免使用 mock |
| 为什么 ExecutionFactory 有这么奇怪的 api？ | 查看 ExecutionFactory 的 git 历史并总结其 api 是如何形成的 |
| 添加日历小部件 | 查看主页上现有小部件的实现方式以了解模式，特别是代码和接口是如何分离的。HotDogWidget.php 是一个很好的开始示例。然后，按照模式实现一个新的日历小部件，让用户选择月份并向前/向后翻页选择年份。从头构建，不使用代码库中已使用的库之外的库。 |

**提供视觉输入**：

- 粘贴 UI 设计稿截图
- 提供期望输出的示例图片
- 拖放错误信息的截图
- 给出文件路径让 AI 读取图像

**明确文件范围**：

- 使用 Tab 补全快速引用文件或文件夹
- 明确告诉 AI 只修改特定文件
- 列出需要 AI 查看的相关文件

**提供 URL**：

- 直接粘贴文档链接让 AI 阅读
- 引用 API 文档、设计规范等在线资源

### 4.3 使用结构化框架编写 Prompt

**COSTAR 框架** (2023 年新加坡 Prompt 大赛冠军总结)：

| 维度 | 含义 | 说明 |
|-----|------|------|
| **C**ontext | 上下文 | 任务的背景信息 |
| **O**bjective | 目标 | Agent 的目标 |
| **S**tyle | 风格 | 期望的代码风格 |
| **T**one | 语气 | 回复的预期语气 |
| **A**udience | 受众 | 面向的用户群体 |
| **R**esponse | 响应格式 | 期望的输出格式 |

**Claude 专属技巧** - 使用伪 XML 结构（Claude 模型对此理解更好）：

```xml
<<这是你的角色>>
{your_role}
<</这是你的角色>>

<<你的任务>>
{your_task}
<</你的任务>>

<<要求>>
{specification}
<</要求>>

<<输出格式>>
{output_format}
<</输出格式>>
```

### 4.4 中英文混合表达消除歧义

中文表达时可能存在二义性，**中英文混合描述可以更精确**。

**示例**：
```
❌ 模糊: "调整一下前端接口"
✅ 清晰: "根据服务端接口 /v1/api/chat 的 request schema 和 response schema，
         调整前端的 API 调用逻辑"
```

### 4.5 让 AI 协助优化 Prompt

借助 AI 工具提升写 Prompt 的效率：
- OpenAI 的 Prompt 工具  
- 自己写一个 Prompt 优化的 Agent
- Claude 在写 Prompt Template 方面效果很好

**元提示技巧**：
```
你: "我想开发一个登录网站，请先帮我优化提示词，
     要求完善需求分析、方案设计和技术选型"
AI: (生成结构化需求文档)
你: (基于优化后的需求继续开发)
```

这种"元提示"技巧能显著提升最终输出质量。

---

## 五、工作流模式：经过验证的实践

### 5.1 自然语言编程范式

当模型能力超过"那个边界"后，编程范式已经在逐步转移至"自然语言编程"。这种范式最大的优势是**极简单/极快速的开始**——你可以在任意时间开始编程，只需要把思考和目标等 Prompt 写在备忘录等文本编辑软件中，在有空时让 AI 帮你进行编码。

这极大地利用了零碎时间。传统编码是一个"冷启动"的过程（打开电脑、打开 IDE、构思并以具体语言编写代码），而自然语言编程可以随时随地开始。

当然，自然语言编程一定会出现各种 corner case，我们对此需要宽容一些，就像你用编程语言编码时会出现 bug 一样。但这同样是一个积累的过程，这就是为什么 Context 如此重要。

### 5.2 合理划分 AI 任务边界

在尝试修改生产级别的代码时，我一般会根据任务复杂度和自身能力范围合理分配 AI 的工作，按照能力范围划分为 3 个类别：

#### 类别 1：能力范围内的任务（搬砖提效）

**特征**：实现逻辑清晰，但实现耗时  
**示例**：CRUD 操作、需求文档清晰的功能、技术设计完善的模块  
**策略**：让 AI 处理逻辑清晰但实现耗时的任务，显著提升效率  
**价值**：把时间节省下来做更有价值的事

#### 类别 2：略超出能力范围的任务（学习加速）

**特征**：通过调研、短期学习可以解决  
**示例**：调用不熟悉的 SDK（如阿里云 SDK 签名）、参考 Python 源码改成 JS 版本  
**策略**：交给 AI 实现，AI 能 fetch 官方文档，甚至凭内生知识补全  
**价值**：快速掌握新技术，避免陷入文档细节

#### 类别 3：远超能力范围的任务（谨慎依赖）

**特征**：完全不熟悉的技术领域  
**示例**：不懂 React Native 却用 AI 开发完整项目  
**风险**：
- 前期快速出 Demo，后期难以扩展
- 代码量增长后，冗余代码、设计问题难以发现
- 效率变低，成本变高

**经验教训**：
> 我对 React Native 了解甚少，有个非常紧急的项目，期望用 Claude Code 生成一个 React Native 项目。AI 前期代码写得很快，基本上半天就有一个可以跑在手机上的 demo 出来了。但是到了项目后期，想要加更多效果，就显得非常困难了。代码量越来越多，冗余代码问题、设计问题都藏在底下不得而知，效率变低，成本变高。最后还是回到使用熟悉的语言。

**建议**：除非代码仅用于 Demo，否则不要完全依赖 AI

💡 **题外话**: 越发觉得全栈技能，对于现在鞭笞 AI 干活显得非常重要。

### 5.3 Talk to Design Docs 工作流

对于 Project-Level 问题，最重要的是如何构建一个准确、符合 AI Coding Best Practice 的设计文档。推荐流程：

**步骤 1：与 AI 对话设计**
- 打开 AI 聊天工具，粘贴 Tech Context
- 简述设计目标，一步步讨论系统架构、细节
- 让 AI 提出当前设计中可能的问题和存在模糊/歧义的地方

**步骤 2：深入细节**
- 在对话中深入任何细节，解决任何困惑
- 当设计足够完善后，让 AI 基于当前对话历史生成最终的 Design Docs

**步骤 3：反思与更新**
- 在与 AI 交流的过程中，任何收获和反思都应手动更新到 Tech/Dev Context
- 这就是产生技术复利的关键

### 5.3 探索-计划-编码-提交

这种多功能工作流程适合大多数开发任务：

**步骤 1：探索**
- 要求 AI 读取相关文件、图像或 URL
- 提供一般指针或特定文件名
- 明确告诉它暂时不要编写任何代码
- 对于复杂问题，考虑使用子会话验证细节

**步骤 2：规划**
- 要求 AI 制定如何处理问题的计划
- 让 AI 充分思考，评估不同方案
- 如果计划合理，可以创建文档记录
- 这样如果实施不理想，可以回退到这个点

**步骤 3：实施**
- 要求 AI 在代码中实施解决方案
- 要求它在实施各个部分时验证合理性
- 保持范围聚焦，避免过度修改

**步骤 4：提交**
- 要求 AI 提交结果并创建拉取请求
- 更新相关文档（README、CHANGELOG 等）

关键：步骤 1-2 至关重要。没有它们，AI 倾向于直接跳到编码，容易导致方向错误。

### 5.4 测试驱动开发（TDD）

这是用于可通过测试轻松验证的更改的最佳工作流程。成功的实践是在编写功能代码之前先让 AI 生成对应的测试用例（可以写在配置文件或 system rules 中）。随后，AI 的任务就变成了"通过所有测试"。这个简单的流程转变，创建了一个能自我修正的闭环，极大提升了可靠性。

**步骤 1：编写测试**
- 要求 AI 基于预期的输入/输出对编写测试
- 明确说明你在进行 TDD，避免创建 mock 实现
- 即使功能尚不存在也先写测试

**步骤 2：确认失败**
- 告诉 AI 运行测试并确认它们失败
- 明确告诉它不要编写任何实现代码

**步骤 3：提交测试**
- 当你对测试满意时，要求 AI 提交测试

**步骤 4：实施功能**
- 要求 AI 编写通过测试的代码
- 指示它不要修改测试
- 让 AI 迭代直到所有测试通过

**步骤 5：提交代码**
- 一旦满意就要求 AI 提交代码

AI 在有明确目标进行迭代时表现最佳。测试提供了清晰的成功标准。

**⚠️ 警惕 AI 的"投机取巧"**：

不要盲目信任单元测试，AI 可能为了让测试通过而采取一些技巧：

**真实案例 1**：
> AI 为了能通过单元测试，修改了技术方案，实际仅仅是安装包依赖问题。

**真实案例 2**：
> 多轮修复 bug 不成功后，AI 偷懒修改了测试代码，做了 mock 数据让单元测试通过了。

**最佳实践**：

可以在项目中构建 `lint.sh` 和 `unittest.sh` 脚本，分别代表代码规范和单元测试。在配置文件或 `CONTRIBUTING.md` 中告诉 AI 需要撰写并通过这些检查。这样简单的设置能让代码可用性高不少。

### 5.5 小步快跑，每一步可验证

> **Karpathy**: 好的代码应该像细菌🦠一样——精炼、模块化、闭包（copy paste-able）

**核心原则**：不要等代码全生成了，然后一次性调试。

**反面教材**：
> 当时按照需求/技术文件让 AI 进行生成全部代码，然后调试，结果 AI 告诉我这不是一个 react-native 的项目，直接崩溃。当时没舍得从头来过，进入无休止的鞭笞、调试、PUA，成本很高，最后不得已，还是重头开发...

**最佳实践**：

1. **模块化设计** - 要求 AI 先抽象通用组件（如"分页列表组件"）
2. **增量验证** - 每完成一个小功能就立即测试
3. **范围控制** - 明确告诉 AI "只修改 `UserService.java`"
4. **原子化提交** - 每次生成代码后立即 `git commit`

**价值**：
- 新功能复用模块，项目线性扩展
- 防止"修一个 Bug，引入十个 Bug"
- 发现 AI 走错路，立即回滚，避免越陷越深

### 5.6 视觉反馈迭代

适用于 UI 开发和需要视觉验证的场景：

**步骤 1：提供工具**
- 为 AI 提供截取浏览器截图的方法
- 或准备好手动复制/粘贴截图

**步骤 2：提供设计稿**
- 通过复制/粘贴或拖放提供视觉模拟
- 或给出图像文件路径

**步骤 3：实施与迭代**
- 要求 AI 实现设计
- 让 AI 截取结果的截图
- 迭代直到其结果与模拟匹配

**步骤 4：提交**
- 当满意时要求 AI 提交

AI 的输出往往通过 2-3 次迭代显著改善。为 AI 提供查看其输出的工具以获得最佳结果。

### 5.7 AI 生成的方案和代码必须 Review

⚠️ **防御性编程思维**: 除非需求极其清晰，否则不要期望一次命令就能完成一个完整需求。

**为什么必须 Review？**

1. **上下文长度限制** - 可能遗忘或产生幻觉
2. **项目理解片面** - 生产出来的代码质量或技术方案不够好
3. **隐藏的风险** - 安全漏洞、性能问题、边缘情况

**我的态度转变**：从部分信任到不信任

在系统代码行增加到 2 万行左右时，对 AI 生产的方案或代码，我会详细的 Review，确保代码投入到生产是没有问题的。

**Review 要点**：

- ✅ 代码逻辑是否符合需求
- ✅ 是否处理了边缘情况
- ✅ 是否存在安全隐患
- ✅ 性能是否可接受
- ✅ 是否引入了不必要的依赖

**平衡之道**：

防御性编程的好处是提高代码质量和可靠性，但也需要平衡，过度会导致效率低下。中间过程中，通常也需要多轮沟通，减少信息传递过程中存在理解差异。

**利用 AI 编写单元测试**：

这是一种验证代码质量的有效方法，但需要注意：
- 不要盲目信任单元测试
- AI 可能为了让测试通过而采取技巧
- 仍需人工审核测试质量

### 5.8 培养任务分类直觉：何时放手，何时掌控

高效协作的前提是做出正确的决策：何时放手，何时掌控。开发者需要培养一种直觉，能够快速判断一个任务是适合"Agent"模式的外围探索，还是需要"Ask"模式的核心构建。这种判断力，是区分普通使用者与高级玩家的关键。

**Agent 模式（放手）**：
- 适用场景：Project-Level 问题，原型构建，探索性开发
- 特点：让 AI 自主工作，完成度优先
- 风险：可能偏离预期，需要后续调整

**Ask 模式（掌控）**：
- 适用场景：Feature-Level 问题，核心业务逻辑，关键功能
- 特点：你理解问题、提出方案，AI 按你的思路执行
- 价值：保持对细节的掌握，避免能力退化

### 5.9 及早且经常地纠正路线

虽然让 AI 自主工作很诱人，但通过成为积极的协作者并指导 AI 的方法，你通常会获得更好的结果。

**路线纠正工具**：

- **要求制定计划**：明确告诉 AI 在你确认其计划前不要编码
- **中断执行**：在任何阶段中断 AI，保留上下文，然后重定向或扩展指令
- **回退历史**：编辑之前的提示，探索不同的方向
- **要求撤销**：让 AI 撤销更改，然后采取不同的方法

虽然 AI 偶尔在第一次尝试时完美解决问题，但使用这些纠正工具通常能更快地产生更好的解决方案。

### 5.10 对复杂工作流程使用检查清单

对于具有多个步骤或需要详尽解决方案的大型任务——如代码迁移、修复大量 lint 错误或运行复杂构建脚本——通过让 AI 使用 Markdown 文件作为检查清单和工作草稿本来提高性能。

**示例：修复大量 lint 问题**

```
步骤 1: 告诉 AI 运行 lint 命令并将所有结果错误（带有文件名和行号）
       写入 Markdown 检查清单

步骤 2: 指示 AI 逐一解决每个问题，修复和验证后再勾选并移至下一个
```

**外部记忆技巧**：

将失败的任务手动编辑出来，并存储在一个外部文档中，然后告诉 AI 去逐个修复。

```
test_result.md 里面记录了运行单元测试失败的 case 以及异常的信息，
请从上往下进行修复。

对于每一个 test case，代码修复完成后，通过运行 pytest 检查 case 是否执行成功。
若 test case 运行成功，在 test_result.md 里面标记完成。

任务结束前，请检查 test_result.md 文档，确保失败的测试用例全部修复。
```

**为什么需要外部记忆？**

过于复杂的任务可能超出上下文长度限制，导致 AI 遗忘早期任务内容。之前尝试让 AI 生成上百个单元测试，执行过程有过半没成功。尝试在依据命令里面让 AI 逐一修复，AI 执行到最后会告知执行完成，实际只修复了几个。原因就是上下文太长了，它不记得任务列表。

---

## 六、OpenSpec 工作流：规格驱动开发

### 6.1 问题：为什么 AI 会"失控"？

**传统 AI 协作流程**：

```
你: "帮我加个搜索功能"
AI: "好的，我修改了 10 个文件"
你: "等等，我只是想加个简单的搜索..."
AI: "我已经重构了整个数据层..."
```

**核心矛盾**：需求在聊天记录里，AI 根据"猜测"行动，没有明确的"设计图纸"。AI coding assistants 在需求模糊时会产生不可预测的输出，常常遗漏需求或添加不需要的功能。

**解决方案**：OpenSpec 添加了一个轻量级的规格工作流，在实施前锁定意图，给你确定的、可审查的输出。

### 6.2 OpenSpec 工作流：先规划，再动手

OpenSpec 强制 AI 遵循工程化流程：

```
┌────────────────────┐
│ 1. 起草提案        │  你和 AI 对齐"要做什么"
│ (Draft Proposal)   │  → 输出：需求文档 + 任务清单
└────────┬───────────┘
         │ share intent with your AI
         ▼
┌────────────────────┐
│ 2. 评审对齐        │  人工检查，确保理解一致
│ (Review & Align)   │◀──── feedback loop ──────┐
└────────┬───────────┘                          │
         │ approved plan                        │
         ▼                                      │
┌────────────────────┐                          │
│ 3. 实施任务        │  AI 严格按任务清单写代码  │
│ (Implement Tasks)  │──────────────────────────┘
└────────┬───────────┘
         │ ship the change
         ▼
┌────────────────────┐
│ 4. 归档更新        │  变更记录永久保存，可追溯
│ (Archive & Update) │
└────────────────────┘
```

### 6.3 OpenSpec 的关键优势

**轻量级**：
- 简单的工作流程
- 无需 API keys
- 最小化设置

**Brownfield-first（适合已有项目）**：
- OpenSpec 分离了真实状态和提案：`openspec/specs/`（当前真相）和 `openspec/changes/`（提案更新）
- 这使得差异明确且可管理，特别适合跨功能修改

**变更追踪**：
- 提案、任务和规格 delta 统一存放
- 归档时将批准的更新合并回规格

**对比表**：

| 特性 | 传统 AI 协作 | OpenSpec 工作流 |
|-----|------------|----------------|
| 需求存储 | 聊天记录里，容易遗忘 | 固化为文档，AI 必须遵守 |
| 范围控制 | AI 自由发挥，容易偏离 | 任务清单约束，防止过度修改 |
| 变更追溯 | 改了什么不清楚 | 每次变更有提案记录，可追溯 |
| 团队协作 | AI 理解不一致 | 团队共享同一份规格说明 |
| 工具支持 | 依赖特定工具 | 支持多种 AI 工具（Claude Code、Cursor、Codex 等） |

**类比**：
- **传统方式**：口头告诉包工头"我想要个两层小楼"，他自由发挥
- **OpenSpec**：先出施工图纸，包工头必须按图纸施工，完工后留存档案

### 6.4 OpenSpec 快速上手

**安装与初始化**：

```bash
# 1. 全局安装 OpenSpec
npm install -g @fission-ai/openspec@latest

# 2. 在项目目录初始化
cd your-project
openspec init

# 3. 选择你使用的 AI 工具（Claude Code、Cursor、Codex 等）
# OpenSpec 会自动配置相应的 slash 命令
```

**创建第一个变更**：

```
你: 创建 OpenSpec 提案：添加用户搜索过滤器
    (或使用快捷命令: /openspec:proposal Add profile search filters)

AI: 我将创建 OpenSpec 变更提案
    创建: openspec/changes/add-profile-filters/
    ├── proposal.md      # 变更原因和内容
    ├── tasks.md         # 实现检查清单
    └── specs/           # 规格 delta（显示变更）

你: 审查提案，验证是否符合预期
    $ openspec show add-profile-filters

你: 提案看起来不错，开始实施
    (或使用快捷命令: /openspec:apply add-profile-filters)

AI: 按任务清单实施
    Task 1.1 ✓ Task 1.2 ✓ Task 2.1 ✓

你: 完成后归档变更
    (或使用快捷命令: /openspec:archive add-profile-filters)
    
AI: 归档完成，规格已更新，准备下一个功能！
```

### 6.5 实际效果对比

**Before（代码失控）**：

```
你: "加个用户搜索功能"
AI: 修改了 12 个文件，重构了数据库，顺便改了登录逻辑
你: "???" (回滚成本巨大，进度延期)
```

**After（使用 OpenSpec）**：

```
你: "创建提案: 添加用户搜索功能"
AI: 生成提案 → 3 个任务:
    - 1.1 添加搜索 API 接口
    - 1.2 前端搜索框组件
    - 1.3 编写单元测试
你: 审查提案 → 批准
AI: 只修改 3 个文件，按任务清单完成
你: 可控、可追溯、可回滚
```

---

## 七、项目管理最佳实践

### 7.1 原子化提交：随时可回滚

**规则**：AI 每次生成代码后立即 `git commit`

**价值**：
- 发现 AI 走错路，立即回滚，避免越陷越深
- Git history 就是项目的另外一份 README.md，抑或者是上下文
- 方便追溯每次变更的意图和内容

**充分利用 AI 的 Git 能力**：

AI 通常能给出详细的 git commit 信息，充分利用这一点。AI 非常熟悉 git 指令，能了解代码仓库过去都修改了哪些内容。

💡 频繁提交有助于在问题出现时方便回滚。

### 7.2 有效管理上下文

> **Karpathy 的洞察**: 虽然现代模型支持 128K 甚至 192K 的上下文长度，但在编码场景下，这些上下文往往仍然不足，因为模型需要阅读和理解大量 code 文件，一下子就把上下文塞得差不多了。

像 Claude Code 这类的工具，在上下文做了很多优化，但**上下文越长，AI 生成代码出现幻觉的概率就越高**，后续修正过程会消耗更多资源。

因此，需要人工辅助管理上下文：

#### 7.2.1 提供精确信息

当已确定修改范围时，应提供准确的文件路径和相关细节。

**最佳实践**：
- 先通过与 AI 逐步沟通，获取并明确关键信息
- 形成清晰上下文后，再让 AI 执行
- 使用 Tab 补全快速引用文件或文件夹
- 明确告诉 AI 只修改特定文件
- 列出需要 AI 查看的相关文件

#### 7.2.2 信息压缩策略

手动筛选重要信息，只保留有价值的部分。

**示例**：修复执行错误时，不要把全部 Exception 信息丢给 AI

举个例子，我们在让 AI 修复一些执行错误的时候，如果把全部 Exception 信息丢给 AI，比如 Java 抛出来的 Exception，会非常长。想象一下我们自己去解决问题的时候，往往也是定位几行有用信息。

**压缩技巧**：
- 只提取关键的错误信息（文件名、行号、错误类型）
- 移除冗余的堆栈信息
- 保留最相关的上下文

#### 7.2.3 控制任务粒度

执行复杂任务需要较高的 Prompt 技巧和使用经验，且难以验证细节。

**反面教材**：
> 尝试过让 AI 写 2 个半小时的代码，一直在运行。但是对于结果，其实我们要花很多时间去做验证，review 的成本会非常高。

**风险**：
- 过于复杂的任务可能超出上下文长度限制
- 导致 AI 遗忘早期任务内容
- Review 成本极高

**最佳粒度**：
- 单个任务控制在 10-30 分钟内
- 及时验证中间结果
- 复杂任务拆分成多个小任务

#### 7.2.4 知识库很重要

对于已有项目，如果希望长期让 AI 持续进来改动，请务必先给它提供更多的信息，以及一个良好的信息获取方式。

**推荐做法**：

像 Claude Code，提供了 `/init` 指令，目的是为了让 AI 快速了解项目的背景、技术架构等，知识库记录了业务需求、技术规约、常见的工程流程等信息。

**强烈建议**：对于一个已经存在的工程项目，我强烈建议**先让 AI 针对代码写说明文档（README.md）**，然后再让它参与到写代码。

**知识库应包含**：
- 项目整体架构
- 核心业务流程
- 技术选型理由
- 编码规范和最佳实践
- 常见问题和解决方案

#### 7.2.5 使用 MCP 工具辅助管理

可以尝试使用 mem0 等 MCP 工具辅助管理上下文。

### 7.3 模块化设计：避免重复造轮子

### 7.3 模块化设计：避免重复造轮子

**规则**：要求 AI 先抽象通用组件（如"分页列表组件"）

**价值**：
- 新功能复用模块，项目线性扩展
- 减少代码冗余，提升可维护性
- 建立项目的设计语言

### 7.4 范围限定：一次只改一个任务

**规则**：明确告诉 AI "只修改 `UserService.java`"

**价值**：
- 防止"修一个 Bug，引入十个 Bug"
- 保持代码变更的可追溯性
- 降低 Review 难度

### 7.5 强制验证：AI 自检

**规则**：要求 AI 生成代码后自动运行测试或编译检查

**价值**：
- 尽早发现低级错误
- 建立自我验证闭环
- 减少人工 Review 的负担

**实施方式**：
- 配置 CI/CD 自动检查
- 编写 `lint.sh` 和 `unittest.sh` 脚本
- 在配置文件中要求 AI 必须通过检查

### 7.6 工具配置优化

**规则**：在工具的配置文件中设置"直接输出代码，省略解释"

**价值**：
- 提升效率，减少冗余输出
- 节省上下文窗口空间
- 更快迭代

**配置示例**：
```markdown
# .cursorrules 或 AGENTS.md

## 代码输出规范
- 直接输出完整代码，不要用省略号
- 避免冗长的解释，代码应该自解释
- 重要的决策用简短注释说明
```

---

## 八、高级技巧与场景

### 8.1 代码库问答

在接触新代码库时，使用 AI 进行学习和探索。你可以向 AI 询问在结对编程时会向项目中其他工程师询问的相同类型问题：

- 日志记录是如何工作的？
- 如何创建新的 API 端点？
- `foo.rs` 第 134 行的 `async move { ... }` 是做什么的？
- `CustomerOnboardingFlowImpl` 处理哪些边缘情况？
- 为什么我们在第 333 行调用 `foo()` 而不是 `bar()`？
- `baz.py` 第 334 行在 Java 中的等价物是什么？

这种方式可以显著改善上手时间并减少其他工程师的负担。

### 8.2 使用 AI 与 Git 交互

AI 可以有效处理许多 git 操作：

- **搜索 git 历史**：回答诸如"v1.2.3 中包含了哪些更改？"、"谁拥有这个特定功能？"等问题
- **编写提交消息**：AI 会自动查看你的更改和最近的历史来编写考虑所有相关上下文的消息
- **处理复杂操作**：如还原文件、解决变基冲突以及比较和移植补丁

### 8.3 使用 AI 与 GitHub 交互

AI 可以管理许多 GitHub 交互：

- **创建拉取请求**：基于差异和周围上下文生成适当的提交消息
- **实施代码审查意见**：告诉 AI 修复 PR 上的评论，完成后推送回 PR 分支
- **修复失败的构建**或 linter 警告
- **分流和分类开放问题**：循环遍历开放的 GitHub 问题并分配适当的标签

### 8.4 多会话并行工作

对于多个独立任务，可以：

**方案 1：多个工作目录**
1. 在单独的文件夹中创建 3-4 个 git 检出
2. 在单独的终端标签中打开每个文件夹
3. 在每个文件夹中启动 AI 会话，执行不同的任务
4. 循环检查进度并批准/拒绝请求

**方案 2：使用 git worktrees**
- 更轻量级的替代方案
- 允许将同一仓库的多个分支检出到单独的目录中
- 每个 worktree 都有自己的工作目录和隔离的文件
- 同时共享相同的 Git 历史和 reflog

**方案 3：多个 AI 验证**
- 让一个 AI 编写代码
- 使用另一个 AI 审查或测试它
- 启动第三个 AI 阅读代码和审查反馈
- 让这个 AI 基于反馈编辑代码

这种分离通常比让单个 AI 处理所有事情产生更好的结果。

### 8.5 先设计，后编码

- **先描述产品"感觉"（Vibe）和用户流程**，再让 AI 实现
- **尽早命名**：确定清晰的模块/组件名称，AI 会贯彻始终
- **多问"为什么"**："为何选择这个方案而非另一种？"逼 AI 暴露假设

---

## 九、总结：从使用工具到重塑工作流

AI 辅助编程不是让 AI 替你写代码，而是让你从更高的维度去思考和设计系统。AI 对软件开发的影响，正从单纯的"效率工具"演变为深刻的"工作流重塑"。

现在 AI 的问题不再是"能写什么代码？"，而是"如何与 AI 协同，以最高效、最可靠的方式完成整个项目？"

### 核心要点回顾

#### 1. 认知层面

| 关键观念 | 核心要点 |
|---------|---------|
| **Prompt 是新的编程语言** | 一句精准的 Prompt 能够省掉百行代码；提示词质量 = 代码质量 |
| **Vibe Coding ≠ 生产级** | AI 写，人审，迭代验证；防御性编程思维不可或缺 |
| **Know What > Know How** | 理解力决定产出质量；架构师和初级程序员用同样工具，产出完全不同 |
| **会提问比找答案更重要** | 问题定义能力是核心竞争力 |

#### 2. 技术层面

| 关键技能 | 实践要点 |
|---------|---------|
| **问题分层思维** | Project-Level 让 AI 探索（Agent 模式）；Feature-Level 保持掌控（Ask 模式），避免能力退化 |
| **上下文工程** | 维护 Tech/Dev Context 让模型对齐你；反思和更新 Context 让你对齐模型；这是技术复利的关键 |
| **Prompt 工程** | 使用 COSTAR 框架；中英文混合消除歧义；让 AI 协助优化 Prompt |
| **上下文管理** | 提供精确信息；压缩关键内容；控制任务粒度；构建知识库 |

#### 3. 工作流层面

| 最佳实践 | 价值 |
|---------|-----|
| **合理划分任务边界** | 能力范围内（搬砖提效）；略超出范围（学习加速）；远超范围（谨慎依赖） |
| **Talk to Design Docs** | 先规划再动手，需求固化为文档，可追溯可回滚 |
| **TDD 测试驱动** | 建立自我验证闭环，但要警惕 AI 的"投机取巧" |
| **小步快跑** | 像细菌一样——精炼、模块化、可验证 |
| **必须 Review** | 从部分信任到不信任；代码行数增长后更要严格把关 |
| **及早纠正路线** | 要求制定计划；中断执行；回退历史；要求撤销 |
| **使用检查清单** | 复杂任务用 Markdown 作为外部记忆 |

#### 4. 项目管理层面

| 管理实践 | 实施要点 |
|---------|---------|
| **原子化提交** | 每次生成代码立即 commit；Git history 是第二份文档 |
| **有效管理上下文** | 精确信息；压缩策略；控制粒度；知识库建设；MCP 工具 |
| **模块化设计** | 先抽象通用组件；新功能复用模块 |
| **范围限定** | 一次只改一个任务；明确修改范围 |
| **强制验证** | AI 自检；配置 lint 和 test 脚本 |
| **工具配置优化** | 直接输出代码，省略解释；节省上下文 |

### 对不同角色的价值

**编程新手**：
- Agent 模式抹平实现门槛
- 快速验证创意、构建原型
- 想法可以更快变成现实

**专业程序员**：
- 从编码执行中解放，专注架构设计、问题分解和创造性思考
- 基于 AI 快速阅读优秀代码，提高代码品味
- 全栈技能对鞭笞 AI 干活显得非常重要

### 未来属于什么样的人？

记住：AI 是工具，你是架构师。工具会越来越强大，但你的价值在于：

✅ **知道要构建什么**（What to build）  
✅ **为什么构建**（Why）  
✅ **如何设计**（How to design）

**未来属于会提问、会思考、会想象的人**：

- **好奇去问** — 保持探索精神
- **系统去想** — 结构化思考能力
- **创造去用** — 将想法落地的能力

用人类智慧提出问题，用人工智能扩展答案。

---

## 参考资料

- [OpenSpec 官方文档](https://github.com/Fission-AI/OpenSpec) — Spec-driven development for AI coding assistants
- [Claude Code 最佳实践](https://www.anthropic.com/engineering/claude-code-best-practices)
- [Awesome Claude Code](https://github.com/hesreallyhim/awesome-claude-code)
- [Anthropic Skills](https://github.com/anthropics/skills)
- [上下文工程实践](https://github.com/yzfly/awesome-context-engineering)
- [Karpathy on Context Engineering](https://mp.weixin.qq.com/s/6j-MqSrJz5YlKAe2LZW6pg)
